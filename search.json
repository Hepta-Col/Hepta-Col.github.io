[{"title":"EM Algorithm","url":"/2022/05/24/EM/","content":"\n\n\n","tags":["Machine Learning","Algorithm"],"categories":["Knowledge Cards","Machine Learning","Projects","Unsupervised Anomaly Detection"]},{"title":"[Latent Outlier] Exposure for Anomaly Detection with Contaminated Data","url":"/2022/05/24/latent-outlier/","content":"\n> Publication: 2022\n>\n> Links: [Paper](https://arxiv.org/pdf/2202.08088v1.pdf)\n>\n> Key Words: Unsupervised Learning, Anomaly Detection\n\n<img src=\"image-20220524234143346.png\" alt=\"image-20220524234143346\" style=\"zoom: 67%;\" />\n\n## Summary\n\nMany anomaly detection methods assume that the training data is clean, which is not always true in reality. When anomaly data is included, the training usually results in degraded performance. The paper solves this problem by alternatively inferring binary labels and updating model parameters in each batch iteration. Experiments show the effectiveness of such method in extensive anomaly detection scenario. \n\n## Problem Statements & Background\n\nGiven a dataset without any label, the model is trained to be able to tell whether a given sample is anomalous or not. A standard assumption about the training dataset is that only normal samples are included, or that anomalous samples take up very small portion. But that’s not true in some real scenarios like medical images and financial transactions. We hope that the model can learn on a corrupted dataset and also has good performance on picking out anomalous data.\n\n## Methods\n\n### Loss Functions\n\nTwo losses are considered.\n\n* loss for normal data $L_n^{\\theta}(x)$ that should be minimized on normal data.\n\n* loss for anomalous data $L_a^{\\theta}(x)$ that should be minimized on anomalous data. \n\nSo put them together, given a set of data $x=\\{x_i\\}_{i=1}^N$, with assigned labels $y=\\{y_i\\}_{i=1}^N$ (1 means anomalous, 0 means normal), model parameters $\\theta$, the loss on this set is defined as $L(\\theta, y)=\\sum_{i=1}^N(1-y_i)L_n^{\\theta}(x_i)+y_iL_a^{\\theta}(x_i)$. In this paper, the authors instantiated the two losses following advanced self-supervised anomaly detection methods MHRot, NTL, and ICL.\n\n### Optimization Problem\n\n#### Hard Label Assignment\n\n$y$ is either assigned 0 or 1. The optimization problem is $min_{\\theta}min_{y\\in Y}L(\\theta, y)$, subject to the constraint that $Y=\\{y\\in \\{0,1\\}^N : \\sum_{i=1}^Ny_i=\\alpha N\\}$, where $\\alpha$ is the predefined contamination rate of anomalous data.  \n\n#### Soft Label Assignment\n\n$y$ is either assigned 0 or 0.5. The optimization problem is $min_{\\theta}min_{y\\in Y}L(\\theta, y)$, subject to the constraint that $Y=\\{y\\in \\{0,0.5\\}^N : \\sum_{i=1}^Ny_i=0.5\\alpha N\\}$, where $\\alpha$ is the predefined contamination rate of anomalous data. The interpretation is that the algorithm is uncertain about whether to treat $x_i$ as a normal or anomalous data point, and compromises between both cases. \n\n### Training Algorithm\n\n#### Calculating Anomaly Score\n\nFor data point $x_i$, $S_i^{train}=L_n^{\\theta}(x_i)-L_a^{\\theta}(x_i)$. The score quantifies the effect of $y_i$ on minimizing $L(\\theta, y)$. The higher, the more normal. \n\n#### Estimating Labels\n\nThese scores are ranked, and the (1 − $\\alpha$)-quantile of the associated labels $y_i$ are assigned the value 0, and the remainder are assigned the value 1. \n\n#### Pseudo Code\n\n<img src=\"image-20220524234154108.png\" alt=\"image-20220524234154108\" style=\"zoom:67%;\" />\n\n### Inference\n\nIn practice we may not want to assume to encounter the same kinds of anomalies that the model encountered during training phase. Hence, the authors refrain from using $L_{\\theta}$ a during testing and score anomalies using only $L_{\\theta}^n$. Note that due to parameter sharing, training $L_{\\theta}^a$ jointly with $L_{\\theta}^n$ has already led to the desired information transfer between both losses. So $S_i^{test}=L_n^{\\theta}(x_i)$.\n\n## Evaluations\n\n### Experiment Setup\n\n#### Backbones\n\n* MHRot\n* NTL\n* ICL\n\n#### Datasets\n\n* Image\n  * CIFAR-10\n  * F-MNIST\n  * MVTEC\n* Tabular\n  * Arrhythmia\n  * Thyroid\n* Video\n  * UCSD\n\n### Results of Interest\n\n<img src=\"image-20220525002851926.png\" alt=\"image-20220525002851926\" style=\"zoom: 80%;\" />\n\n<img src=\"image-20220525003053189.png\" alt=\"image-20220525003053189\" style=\"zoom:80%;\" />\n\n## Ideas\n\n* EM algorithm\n* soft assignment with probabilities\n* in video anomaly detection, treat frames as data points and assign frame-level anomalous scores\n","tags":["Deep Learning","CV","Unsupervised Anomaly Detection"],"categories":["Paper Notes","CV","Projects","Anomaly Detection","Unsupervised Anomaly Detection","Image Anomaly Detection"]},{"title":"[LogicNLG] Logical Natural Language Generation from Open-Domain Tables","url":"/2022/05/24/LogicNLG/","content":"\n> Publication: 2020 ACL\n>\n> Links: [Paper](https://arxiv.org/abs/2004.10404), [Interpretation (CN)](https://blog.csdn.net/weixin_42802447/article/details/115366577), [Code](https://github.com/wenhuchen/LogicNLG)\n>\n> Key Words: NLG, table-to-text\n\n## Summary\n\nExisting NLG methods put limited emphasis on logical inference. The authors improved LM with such ability by a new training task called Logical NLG, accompanied with a new metric which evaluates the fidelity of the generated language. What’s more, they built a new dataset, providing a new testbed for logical inference. \n\n## Problem Statements & Background\n\nGiven a table, large pretrained LMs are able to generate fluent and coherent texts, but they lack fidelity: the generated text should be consistent with the underlying data, knowledge, or meaning representation. Recent work have proposed several methods to tackle surface-level fidelity problems, but actually they are just restating the facts in the underlying data. Here is an example:\n\n<img src=\"image-20220524151519647.png\" alt=\"image-20220524151519647\" style=\"zoom: 67%;\" />\n\nWe hope that the LM is able to generate beyond superficial facts by inferring the facts that can be entailed by the presented facts, like the ones shown in the box “Logical Natural Language Generation”. \n\n## Methods\n\n### New Task and New Metric\n\nTo equip LM with the stronger table-to-text generation ability, the authors propose a new task “logical NLG”, which means the generated texts should achieve high scores in **logical fidelity**. Existing IE-based metrics for evaluating generation have two major problems:\n\n<img src=\"image-20220524154947578.png\" alt=\"image-20220524154947578\" style=\"zoom: 67%;\" />\n\n To avoid these problems, the authors proposed several alternating automatic metrics:\n\n#### Parsing-based Evaluation\n\n It directly extracts the meaning representation from the generated sentence and executes it against the table to verify its correctness. \n\n<img src=\"image-20220524155657103.png\" alt=\"image-20220524155657103\" style=\"zoom: 67%;\" />\n\nThe sentence is represented by an expression (gray box), and then the expression could be executed against the table according to the fixed rule of the expression. \n\n#### NLI-based Evaluation\n\nThe NLI model is based on TableBERT, which linearizes the table into textual form and uses it as the evidence for natural language inference.\n\n<img src=\"image-20220524155727867.png\" alt=\"image-20220524155727867\" style=\"zoom:67%;\" />\n\n#### Adversarial Evaluation\n\nManually annotate adversarial examples for the test/validation set by simply changing minimum words to revert the logic of the sentence. Such adversarial examples preserve linguistic components like length and style except the logic-related words to specifically disentangle the generation model’s reasoning skill.\n\n<img src=\"image-20220524155755136.png\" alt=\"image-20220524155755136\" style=\"zoom:67%;\" />\n\n#### Discussion\n\n|      | Parsing-based (SP-Acc)                                       | NLI-based (NLI-Acc)                                          | Adversarial (Adv-Acc)                                        |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Pros | unbiased, as it measures the peak samples in the model’s likelihood | unbiased, as it measures the peak samples in the model’s likelihood | accurate in terms of reflecting the model’s reasoning capability on the given samples |\n| Cons | based on imperfect models, and thus evaluation score is inaccurate: more sensitive to number/calculation errors | based on imperfect models, and thus evaluation score is inaccurate: more sensitive to semantic errors | as the provided samples might not lie in the high-confidence area of the model’s distribution, it is biased in reflecting the model’s general reasoning capability |\n\n### New Dataset\n\nThe new dataset is built based on TabFact, a table-based fact-checking dataset with rich logical inferences in the annotated statements. This dataset contains rich logical inference, and every annotated sentence involves certain types of inference with minimum domain-specific knowledge. Sentences are made short, to focus on the problem of inference rather than linguistic complexity.\n\n<img src=\"image-20220524152917190.png\" alt=\"image-20220524152917190\" style=\"zoom: 50%;\" />\n\n### Training\n\n#### Adversarial Regularization\n\nFirst perform entity resolution to locate all the numbers, count, entities in the sentence and then randomly replace them with entities or numbers appearing in the table $T$. These perturbed samples are used as adversarial examples to regularize the model’s behavior.\n\n<img src=\"image-20220524170034608.png\" alt=\"image-20220524170034608\" style=\"zoom:67%;\" />\n\nMaximize the probability of correct samples, and minimize the probability of incorrect samples.\n\n#### Reinforcement Learning\n\nTo improve logical consistency of the generated sentence.\n\n<img src=\"image-20220524170251225.png\" alt=\"image-20220524170251225\" style=\"zoom: 67%;\" />\n\nThe full sentence receives a binary score $r(Y, T)$ from the semantic parser as reward, which denotes how good the sentence is, semantically.\n\n### Generation\n\nThe authors utilize coarse-to-fine generation to avoid the problem of mismatch between sequence order and logical order. \n\n<img src=\"image-20220524171228070.png\" alt=\"image-20220524171228070\" style=\"zoom:80%;\" />\n\nThe generation is composed of two phases:\n\n1. generate template. Use the entity linker to identify the entities and numbers in the original sentence $Y$ and replace them with placeholders.\n2. fill the placeholders. \n\n## Evaluations\n\n### Experiment Setup\n\n* Non-pretrained models: LSTM, Transformer\n* Pretrained models: Huggingface’s BERT & GPT-2\n\n### Results of Interest\n\n![image-20220524171658708](image-20220524171658708.png)\n\n## Conclusions\n\n1) Pre-Trained LM can significantly boost both the fluency and logical fidelity metrics\n2) RL and Adversarial Training are trading fluency for fidelity\n3) Coarse-to-Fine generation can help partially alleviate the fidelity issue while maintaining high language fluency\n","tags":["Deep Learning","NLP","NLG","Table-To-Text"],"categories":["Paper Notes","NLP","Projects","NLG","Table Pretraining"]},{"title":"[RTFM] Weakly-supervised Video Anomaly Detection with Robust Temporal Feature Magnitude Learning","url":"/2022/05/23/RTFM/","content":"\n> Publication: 2021 ICCV\n>\n> Links: [Paper](https://arxiv.org/pdf/2101.10030.pdf), [Interpretation (CN)](https://www.cnblogs.com/lhiker/articles/15599788.html), [Code](https://github.com/tianyu0207/RTFM)\n>\n> Key Words: Weakly Supervised Video Anomaly Detection, Multiple Instance Learning\n\n![image-20220523172333347](image-20220523172333347.png)\n\n## Summary\n\nExisting MIL loss has several drawbacks, and the authors improve the loss definition by using top-k selection and scoring segments according to feature magnitudes. \n\n## Problem Statements & Background\n\nGiven a video, the model is supposed to tell whether it contains anomaly events. In weakly supervised senario, the model is trained only with video-level labels, i.e. anomaly or not. Several past work have focused on multiple instance learning (MIL), which models the input video as a bag of video segments. The first version of MIL loss is defined by Sultani et al, which considers only the most anomaly segment in the video bag. If the model initially chooses a normal one and assigns a high score to it, this error would be exacerbated in the following training process; in addition, anomaly events usually occur in multiple segments of a video, and this MIL loss would result in the model's losing chances to learn on those valuable anomaly video segments. \n\n## Methods\n\nFirst, a video $X$ would break up into $T$ snippets. In practice, $T=32$. For each of the snippet $X_i$, it would be passed into a pretrained encoder (C3D, I3D) and become a feature $f_i$. And the features, denoted as $F={f_i}$ would then go to the MTN, which is illustrated below:\n\n<img src=\"image-20220523174001679.png\" alt=\"image-20220523174001679\" style=\"zoom:80%;\" />\n\nThis module is basically based on self-attention. After all these intermediate steps, $F$ would be mapped to $x$, with one $f_i$ corresponding to one $x_i$. Finally, a classifier is applied to $x$ and get a binary logits. \n\nTwo losses are defined for training:\n\n1.  improved MIL loss (RTFM loss): \n\n<img src=\"image-20220523174516365.png\" alt=\"image-20220523174516365\" style=\"zoom:67%;\" />\n\nThis loss aims at maximizing the separability between normal videos and abnormal videos. To define the separability:\n\n<img src=\"image-20220523174801028.png\" alt=\"image-20220523174801028\" style=\"zoom: 50%;\" />\n\n<img src=\"image-20220523174833204.png\" alt=\"image-20220523174833204\" style=\"zoom:50%;\" />\n\nwhere $g_{\\theta, k}$ is measuring the mean magnitude of the top-k features with highest magnitudes. \n\n2. binary classification loss:\n\n<img src=\"image-20220523174541257.png\" alt=\"image-20220523174541257\" style=\"zoom:67%;\" />\nThis is nothing but a binary cross-entropy loss.\n\n## Evaluations\n\n### Experiment Setup\n\ndatasets:\n\n* UCF-Crime\n* XD-Violence\n* Shanghai-Tech\n* UCSD-Peds\n\n### Results of Interest\n\n<img src=\"image-20220523175255139.png\" alt=\"image-20220523175255139\" style=\"zoom: 67%;\" />\n\n<img src=\"image-20220523175324561.png\" alt=\"image-20220523175324561\" style=\"zoom:67%;\" />\n","tags":["Deep Learning","CV","Weakly Supervised Video Anomaly Detection"],"categories":["Paper Notes","CV","Projects","Anomaly Detection","Video Anomaly Detection","Human Aggression Detection"]},{"title":"[Turning Tables] Generating Examples from Semi-structured Tables for Endowing Language Models with Reasoning Skills","url":"/2022/05/21/turning-tables/","content":"\n> Publication: 2021\n>\n> Links: [Paper](https://arxiv.org/abs/2107.07261), [Code](https://github.com/oriyor/turning_tables)\n>\n> Key Words: reasoning, semi-structured table\n\n![image-20220515170620320](image-20220515170620320.png)\n\n## Summary\n\nExisting LMs lack reasoning skills, and the authors tackle this problem by pretraining LMs with semi-structured tables, which are used to generate different sets containing 16 kinds of question-context-answer triplets, in order to endow LMs with various reasoning skills.\n\n## Problem Statements & Background\n\nLarge pretrained LMs have been proved to struggle in performing symbolic reasoning operations. Past work on improving reasoning skills mainly have two flavors: 1) adding specialized components for specific skills (numerical reasoning, temporal reasoning), 2) generating synthetic examples at scale (using grammars, templates, question generation models).\n\n## Methods\n\nThe authors argue that **semi-structured tables** are a valuable resource for automatic generation of training data that will endow LMs with reasoning skills. Tables can be crawled from the web, and question-context-answer (q-c-a) triplets can be generated from the tables. \n\nExamples of q-c-a:\n\n<img src=\"image-20220515172904363.png\" alt=\"image-20220515172904363\" style=\"zoom: 67%;\" />\n\nFollowing is the overall architecture:\n\n<img src=\"image-20220515173107157.png\" alt=\"image-20220515173107157\" style=\"zoom: 67%;\" />\n\n### Data Generation\n\nThe authors generate table data by crawling tables from Wikipedia, and applying **16 different example generators (EGs)** on each table. Each EG corresponds to a particular reasoning skill (composition, numerical comparison, etc.), and comprises a small set of question templates. Variables in the templates are filled with content from the table, and the structure of the table allows to compute the answer automatically. The context is a list of facts generated from the table that contain facts required for answering the question as well as distractor facts.\n\n### Error-driven Sampling\n\nThe training process involves learning on multiple results from different EGs, so a proper multi-task training method is required. The authors make the training focus on the reasoning skills that the model still lacks, i.e. **error-driven sampling**. \n\nPast work have proposed uniform sampling, error sampling, etc.. An issue with error sampling is that if the error rate is high for a task and learning it is slow, the model will spend most time on that task at the expense of all other tasks, which may lead overall to low data efficiency. The authors put forward **momentum sampling**, which samples examples from a task in proportion to its rate of improvement, putting most probability mass on skills that are improving quickly.\n\n<img src=\"image-20220515181058227.png\" alt=\"image-20220515181058227\" style=\"zoom:67%;\" />\n\n### Finetune\n\nThe authors finetune the Pre-trained for Reasoning Model, **PReasM**, on three RC datasets that require reasoning: DROP, IIRC, and MMQA. \n\n## Evaluations\n\n### Experiment Setup\n\nModels\n\n* baseline: T5 (T5-base, T5-large)\n\nDatasets & Metrics\n\n* DROP: F1, EM\n* IIRC: F1, EM\n* MMQA: F1, EM\n\n### Results of Interest\n\n#### Performance on each dataset\n\n<img src=\"image-20220515181941958.png\" alt=\"image-20220515181941958\" style=\"zoom:67%;\" />\n\n#### Effect of new sampling strategy\n\n<img src=\"image-20220515182134219.png\" alt=\"image-20220515182134219\" style=\"zoom:67%;\" />","tags":["Deep Learning","NLP","Table Pretraining","Reasoning"],"categories":["Paper Notes","NLP","Projects","Table Pretraining"]},{"title":"Hexo Manual","url":"/2022/05/21/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n<!--more-->\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","categories":["Documentations"]}]