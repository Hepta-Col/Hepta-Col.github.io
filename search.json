[{"title":"[D2L] Dimensionality-Driven Learning with Noisy Labels","url":"/2022/05/26/D2L/","content":"\n> Publication: 2018 ICML\n>\n> Links: [Paper](https://proceedings.mlr.press/v80/ma18d.html), [Code](https://github.com/xingjunm/dimensionality-driven-learning)\n>\n> Key Words: Adversarial Learning, Noisy Labels\n\n## Summary\n\nTraining data with noisy labels pose challenges for training DNNs. The authors investigated in the dimensionality of features and found that there exists large difference between learning on data with all-clean labels and learning on data with some noisy labels. Based on this finding, they propose D2L, a new DNN training framework to monitor the dimensionality information and adapt the loss function.\n\n## Problem Statements & Background\n\nStudies have shown that DNNs may generalize poorly for datasets which contain a high proportion noisy (incorrect) labels, and existing methods to solve such problem (manually cleaning the labels, building a noise model) have various limitations. \n\n## Methods\n\n### Local Intrinsic Dimensionality (LID)\n\nTo avoid complexity and focus only on this paper, here is a very trivial understanding of $LID$: \n\n==Given a data sample $x$, $LID$ is an approximation of the **dimension** of the **subspace** containing x that would best fit the data distribution in the **vicinity** of x.==\n\nIn practice, scholars usually use the estimation of $LID$. While in this paper, the authors used $LID$ estimation, $\\hat{LID}$, through batch sampling, which is defined below:\n\n<img src=\"image-20220526171418415.png\" alt=\"image-20220526171418415\" style=\"zoom:67%;\" />\n\nwhere $x$ is a data sample, $X_B$ is a batch drawn from the entire dataset $X$, $k$ is the number of neighbors, $g=h^{(L-1)}$ is the output of the second-to-last layer of the DNN, $h:P\\rarr \\R^c$ is an $L$-layer DNN, $h^{(i)}$ is the intermediate transformation of the $i^{th}$ layer, $r_i(g(x),g(X_B))$ is the distance of $g(x)$ to its $i^{th}$ nearest neighbor in the transformed set $g(X_B)$, and $r_{max}(g(x),g(X_B))$ is the radius of the neighborhood.\n\n### Two-stage Learning\n\nThe authors found that DNN trained with data containing noisy labels would go through a two-stage learning process:\n\n<img src=\"image-20220526172330188.png\" alt=\"image-20220526172330188\" style=\"zoom:80%;\" />\n\nHere is the reference of the original explanation of such patterns:\n\n> For **training data with clean labels**, the network gradually transforms the data to subspaces of low dimensionality. Once the subspaces of the lowest dimensionality has been found, the network effectively stops learning: the test accuracy stabilizes at its highest level and the dimensionality stabilizes at its lowest. \n>\n> On the other hand, for **training data with noisy labels**, the network initially learns a transformation of the data to subspaces of lower dimensionality, although not as low as when training on data with clean labels. Thereafter, the network progressively attempts to accommodate noisy labels by increasing the subspace dimensionality.\n\nThey call the first stage *dimensionality compression*, where the dimensionalities associated with the underlying data manifold are learned, and the second *dimensionality expansion*, where the subspace dimensionalities steadily increase as the learning process tries to fit the noisy data.\n\n### Dimensionality-Driven Learning Strategy (D2L)\n\nBased on the previous finding, the main issue to prevent learning on noisy data is to identify turning point between the two stages and to adapt the loss function according to the $LID$ scores. \n\nGiven a training sample $x$, let’s denote the original label as $y$ and the predicted label as $\\hat{y}$, and both of them are one-hot vectors. Denote $(\\hat{LID_0}, \\hat{LID_1},..., \\hat{LID_T})$ as the sequence of $LID$ scores, where $\\hat{LID_i}$ is computed at the $i^{th}$ epoch by averaging over the batch samples. \n\n#### Interpolation: Avoid Dimensionality Expansion\n\nTo reduce the effect of noisy labels on learning the true data distribution, an adaptive $LID$-corrected label formulation is as follows:\n\n<img src=\"image-20220526173706141.png\" alt=\"image-20220526173706141\" style=\"zoom: 67%;\" />\n\nwhere $\\alpha_i$ is a factor at the $i^{th}$ training epoch indicating the weight of original label, defined as:\n\n<img src=\"image-20220526173817127.png\" alt=\"image-20220526173817127\" style=\"zoom:67%;\" />\n\nwhere $\\lambda=\\frac{i}{T}$ indicates decreasing confidence in the raw labels when the training proceeds to the dimensionality expansion stage (that is, when $LID$ begins to increase). So if the dimensionality expands (the fraction being greater than 1), we hope the model tends to decrease the subspace dimensionality (favor the current predicted label) instead of learning from original labels. Finally, the $LID$-correct loss is defined as:\n\n<img src=\"image-20220526174116901.png\" alt=\"image-20220526174116901\" style=\"zoom:67%;\" />\n\nwhich is a variation of cross-entropy loss. Here $N$ is the total number of training samples, and $P(y_n^*|x_n)$ is the predicted class probability of $y_n^*$ given $x_n$. \n\n#### Identify Turning Point\n\nThe authors employed an epoch window of size $w \\in [1, T − 1]$ so as to allow $w$ epochs of initialization for the network. The turning point is flagged when the $LID$ score of the current epoch is two standard deviations higher than the mean $LID$ score of the $w$ preceding epochs. Right after the turning point, the model is rolled back the state of the previous epoch and begin the interpolation. \n\n#### Algorithm\n\n<img src=\"image-20220526174810216.png\" alt=\"image-20220526174810216\" style=\"zoom:80%;\" />\n\n## Evaluations\n\n### Experiment Setup\n\n* Datasets: MNIST, SVHN, CIFAR-10/100\n* Models: CNN\n\n* Others: Noisy labels were generated by introducing symmetric noise, in which the labels of a given proportion of training samples are flipped to one of the other class label, selected with equal probability\n\n### Results of Interest\n\n![image-20220526175150618](image-20220526175150618.png)\n\n## Conclusions\n\nWhen DNN is trained with data containing noisy labels, dimensional compression occurs early in the learning process, followed by dimensional expansion as the process begins to overfit on the noisy labels. D2L algorithm could effectively avoid such overfitting.\n","tags":["Deep Learning","Adversarial Learning","Interpretability"],"categories":["Paper Notes","Adversarial Learning","Projects","Unsupervised Anomaly Detection"]},{"title":"MIST","url":"/2022/05/25/MIST/","content":"\n> Publication: 2022 ACL\n>\n> Links: [Paper](), [Interpretation (CN)](), [Code]()\n>\n> Key Words: \n\n## Summary\n\n\n\n## Problem Statements & Background\n\n\n\n## Methods\n\n\n\n## Evaluations\n\n### Experiment Setup\n\n\n\n### Results of Interest\n\n\n\n## Conclusions\n\n\n\n## Questions\n\n\n\n## Ideas\n\n\n\n## Selected References\n\n","tags":["Deep Learning","CV","Weakly Supervised Video Anomaly Detection"],"categories":["Paper Notes","CV","Anomaly Detection","Projects","Video Anomaly Detection","Human Aggression Recognition"]},{"title":"[WSAL] Localizing Anomalies from Weakly-Labeled Videos","url":"/2022/05/25/WSAL/","content":"\n> Publication: 2021\n>\n> Links: [Paper](https://arxiv.org/pdf/2008.08944.pdf), [Code](https://github.com/ktr-hubrt/WSAL)\n>\n> Key Words: Weakly Supervised Video Anomaly Detection, Multiple Instance Learning, Denoising, Localization\n\n<img src=\"image-20220525201028593.png\" alt=\"image-20220525201028593\" style=\"zoom: 80%;\" />\n\n## Summary\n\nFew studies on weakly supervised video anomaly detection have focused on temporal localization of anomaly frames. This work filled this gap by using a high-order context encoding module and handcrafted anomaly frames. In addition, a denoising method was put forward to lower the model’s sensitivity to noises. And the authors built a traffic-specific video anomaly detection dataset: TAD.\n\n## Problem Statements & Background\n\nGiven a video, the model is supposed to tell whether it contains anomaly events, and also localize the anomalies in the video frame sequence. In a weakly supervised scenario, the model is trained only with video-level labels, i.e. anomaly or not. Previous methods have reached good performances, but they are tested on the overall videos, which somewhat conceals the poor capability of temporal localization of anomaly frames. \n\n<img src=\"image-20220525200153611.png\" alt=\"image-20220525200153611\" style=\"zoom:67%;\" />\n\nAs shown above, in terms of specifying anomalous frames, two previous work reach AUROC only a little bit higher than 50%. There still exists a large space for improving ability of temporal localization of anomalies.\n\n## Methods\n\nFirst, a video $X$ would break up into $m$ snippets. For each of the snippet $X_i$, it would be passed into a classic convolution encoder (C3D, I3D) and become a feature $x_i$. \n\nTo predict whether a video is normal or abnormal, the authors define the score function as:\n\n![image-20220525202517964](image-20220525202517964.png)\n\nwhere $\\psi$ is a **high-order context encoder**, $f$ is a **margin distance metric**, $S$ is the score of a video that computes the maximum relative distance of pairwise frame positions. \n\nTraining samples are augmented to generate two types of data: noise data and pseudo-location data.\n\nFinally, the total loss function is defined as:\n\n![image-20220525203622185](image-20220525203622185.png)\n\n### High-order Context Encoding (HCE)\n\n\n\n### Handcrafted Anomalies\n\n\n\n### Noise Stimulation\n\n\n\n## Evaluations\n\n### Experiment Setup\n\n\n\n### Results of Interest\n\n\n\n## Conclusions\n\n\n\n## Questions\n\n\n\n## Ideas\n\n\n\n## Selected References\n\n","tags":["Deep Learning","CV","Weakly Supervised Video Anomaly Detection"],"categories":["Paper Notes","CV","Anomaly Detection","Projects","Video Anomaly Detection","Human Aggression Recognition"]},{"title":"EM Algorithm","url":"/2022/05/25/EM/","content":"\n> PREREQUISITES: [Gaussian Mixture Model (GMM)](), [Clustering](), [Maximum Likelihood Estimation (MLE)]()\n\n## Two Problems at Hand\n\n### Problem A\n\nWe have two bags of candies. Each candy has two features: flavor (cherry or orange) and wrapper (red or green). Each bag has three parameters: $\\theta$ is the probability that a candy comes from the bag; $\\theta_F$ is the probability that the flavor is cherry given that the candy comes from the bag; $\\theta_W$ is the probability that the wrapper is red given that the candy comes from the bag.\n\n* *Question*: Now we mix the two bags of candies. Use the observation of the mixture of candies, calculate $\\theta, \\theta_{F1}, \\theta_{F2}, \\theta_{W1}, \\theta_{W2}$. \n* *Analysis*: If we knew **which bag (1 or 2) each candy comes from (i.e. assignments)**, the problem becomes “for each bag of candies, calculate the probabilities of ……”, which can be done by just counting. But unfortunately we don’t. Actually we could know it if we first know the parameters: using those parameters we could finally calculate **probabilities that each candy comes from each bag**. However, the parameters are exactly what we are gonna solve! How could we know them first!\n\n### Problem B\n\nWe have many data points on a 2-d data space. We want to recover the bivariate GMM models from these raw data, i.e. given figure b, generate figure a. \n\n<img src=\"image-20220525125545663.png\" alt=\"image-20220525125545663\" style=\"zoom:67%;\" />\n\n* *Question*: How are you gonna do that?\n\n* Analysis: If we knew **which component (orange, purple, or green) generated each data point (i.e. assignments)**, the problem becomes “for each set of data points that belong to the same component, fit a Gaussian model on this set of data points”. But unfortunately we don’t. Actually we could know it if we first know the model parameters: using those parameters we could finally calculate **probabilities that each component generates each data point**. However, the models parameters are exactly what we are gonna solve! How could we know them first!\n\n## Why Are We Stuck?\n\nFor the two problems above, the **assignments** are called ==**hidden variables**== or ==**latent variables**==, because we don’t know their values when we want to find the parameters. \n\nA general form of the problems like the two above is: given the statistical model which generates a set of observed data $X=\\{x_1, x_2, ..., x_m\\}$, a set of unobserved data $Z=\\{z_1, z_2, ..., z_n\\}$, and a vector of unknown parameters $\\theta$. Then the **MLE function** becomes: \n\n$L(\\theta;X)=\\log P(X|\\theta)=\\sum_{i=1}^m\\log p(x_i|\\theta)=\\sum_{i=1}^m\\log{\\sum_{j=1}^np(x_i, z_j| \\theta)}=\\sum_{i=1}^m\\log{\\sum_{j=1}^np(x_i|z_j, \\theta)p(z_j|\\theta)}$.\n\nHowever, this objective function is often intractable since the random variable $Z$ is unobserved and the distribution of $Z$ is unknown (i.e. we don’t know $p(z_j|\\theta)$). We need the values of the latent variables to estimate the parameters, meanwhile we also need the parameters to estimate the values of the latent variables. \n\n## EM Algorithm\n\nNow EM algorithm comes into play. When searching for appropriate model parameters in the presence of latent variables, EM algorithm is one of the alternate formulations of MLE.\n\nThe idea of EM is very intuitive. Again we use the general problem statement above. First, initialize parameters $\\theta$ to some random value. We iterates the following two steps until convergence:\n\n* **E-step** (Expectation): Given current estimates of parameters $\\theta^{(t)}$, along with the observed data $X$, we can calculate the distribution of $Z$. For example, if $Z$ is discrete:\n\n  | $Z=$ | 1    | 2    | 3    |\n  | ---- | ---- | ---- | ---- |\n  | $P$  | 0.2  | 0.3  | 0.5  |\n\n  Define $Q(\\theta|\\theta^{t})=E_Z[\\log{P(X,Z|\\theta)}|X, \\theta^{(t)}]=\\sum_ZP(Z|X, \\theta^{(t)})\\log P(X,Z|\\theta)$, i.e. weighted sum of $\\log P(X|\\theta)$.\n\n* **M-step** (Maximization): Find the parameters that maximize the expectation, i.e. $\\theta^{(t+1)}=argmax_{\\theta}Q(\\theta|\\theta^{(t)})$. \n\nIn one sentence: randomly initialize parameters, and then iteratively calculate the distribution of latent variables and calculate parameters by likelihood maximization (BTW, notice that EM is sensitive to initialization!).\n\n## 1-D Example\n\nHere is a toy example of using EM to fit a GMM model on 1-D data. Remember that the latent variables here are the assignments of the points.\n\nWe start with a bunch of points without labels. We only know that they came from two Gaussians.\n\n<img src=\"image-20220525172133668.png\" alt=\"image-20220525172133668\" style=\"zoom:80%;\" />\n\nFirst we place two random Gaussians on these data:\n\n<img src=\"image-20220525172224766.png\" alt=\"image-20220525172224766\" style=\"zoom:80%;\" />\n\nThen, for each of the points, we are asking: how likely it is to come from yellow Gaussian and blue Gaussian?\n\nWe know that for a Gaussian model with parameters $\\theta$, $P(x_i|\\theta)=\\frac{1}{\\sqrt{2\\pi\\sigma_{\\theta}^2}}exp(-\\frac{(x_i-\\mu_{\\theta})^2}{2\\sigma_{\\theta}^2})$. Using this, we can calculate $P(a|x_i)=\\frac{P(x_i|a)P(a)}{P(x_i|a)P(a)+P(x_i|b)P(b)}, P(b|x_i)=\\frac{P(x_i|b)P(b)}{P(x_i|a)P(a)+P(x_i|b)P(b)}$. So we are actually “coloring” the points like:\n\n<img src=\"image-20220525173348156.png\" alt=\"image-20220525173348156\" style=\"zoom:80%;\" />\n\nOnce the “coloring” is done, we can re-estimate the parameters:\n\n$\\mu_a=\\frac{P(a|x_1)x_1 + P(a|x_2)x_2 + .. + P(a|x_n)x_n}{P(a|x_1)+P(a|x_2)+...+P(a|x_n)}, \\mu_b=\\frac{P(b|x_1)x_1 + P(b|x_2)x_2 + .. + P(b|x_n)x_n}{P(b|x_1)+P(b|x_2)+...+P(b|x_n)}$;\n\n$\\sigma_a=\\frac{P(a|x_1)(x_1-\\mu_1)^2 + P(a|x_2)(x_2-\\mu_2)^2 + .. + P(a|x_n)(x_n-\\mu_n)^2}{P(a|x_1)+P(a|x_2)+...+P(a|x_n)}, \\sigma_b=\\frac{P(b|x_1)(x_1-\\mu_1)^2 + P(b|x_2)(x_2-\\mu_2)^2 + .. + P(b|x_n)(x_n-\\mu_n)^2}{P(b|x_1)+P(b|x_2)+...+P(b|x_n)}$. \n\nAnd we continue following this manner. Finally, it would converge to:\n\n<img src=\"image-20220525174147971.png\" alt=\"image-20220525174147971\" style=\"zoom:80%;\" />\n\n## References\n\n* https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm\n* https://machinelearningmastery.com/expectation-maximization-em-algorithm/\n* https://www.youtube.com/watch?v=iQoXFmbXRJA&list=RDCMUCs7alOMRnxhzfKAJ4JjZ7Wg&index=5\n\n","tags":["Machine Learning","Algorithm"],"categories":["Knowledge Cards","Machine Learning","Projects","Unsupervised Anomaly Detection","Human Aggression Recognition"]},{"title":"[Latent Outlier] Exposure for Anomaly Detection with Contaminated Data","url":"/2022/05/24/latent-outlier/","content":"\n> Publication: 2022\n>\n> Links: [Paper](https://arxiv.org/pdf/2202.08088v1.pdf)\n>\n> Key Words: Unsupervised Learning, Anomaly Detection\n\n<img src=\"image-20220524234143346.png\" alt=\"image-20220524234143346\" style=\"zoom: 67%;\" />\n\n## Summary\n\nMany anomaly detection methods assume that the training data is clean, which is not always true in reality. When anomaly data is included, the training usually results in degraded performance. The paper solves this problem by alternatively inferring binary labels and updating model parameters in each batch iteration. Experiments show the effectiveness of such method in extensive anomaly detection scenario. \n\n## Problem Statements & Background\n\nGiven a dataset without any label, the model is trained to be able to tell whether a given sample is anomalous or not. A standard assumption about the training dataset is that only normal samples are included, or that anomalous samples take up very small portion. But that’s not true in some real scenarios like medical images and financial transactions. We hope that the model can learn on a corrupted dataset and also has good performance on picking out anomalous data.\n\n## Methods\n\n### Loss Functions\n\nTwo losses are considered.\n\n* loss for normal data $L_n^{\\theta}(x)$ that should be minimized on normal data.\n\n* loss for anomalous data $L_a^{\\theta}(x)$ that should be minimized on anomalous data. \n\nSo put them together, given a set of data $x=\\{x_i\\}_{i=1}^N$, with assigned labels $y=\\{y_i\\}_{i=1}^N$ (1 means anomalous, 0 means normal), model parameters $\\theta$, the loss on this set is defined as $L(\\theta, y)=\\sum_{i=1}^N(1-y_i)L_n^{\\theta}(x_i)+y_iL_a^{\\theta}(x_i)$. In this paper, the authors instantiated the two losses following advanced self-supervised anomaly detection methods MHRot, NTL, and ICL.\n\n### Optimization Problem\n\n#### Hard Label Assignment\n\n$y$ is either assigned 0 or 1. The optimization problem is $min_{\\theta}min_{y\\in Y}L(\\theta, y)$, subject to the constraint that $Y=\\{y\\in \\{0,1\\}^N : \\sum_{i=1}^Ny_i=\\alpha N\\}$, where $\\alpha$ is the predefined contamination rate of anomalous data.  \n\n#### Soft Label Assignment\n\n$y$ is either assigned 0 or 0.5. The optimization problem is $min_{\\theta}min_{y\\in Y}L(\\theta, y)$, subject to the constraint that $Y=\\{y\\in \\{0,0.5\\}^N : \\sum_{i=1}^Ny_i=0.5\\alpha N\\}$, where $\\alpha$ is the predefined contamination rate of anomalous data. The interpretation is that the algorithm is uncertain about whether to treat $x_i$ as a normal or anomalous data point, and compromises between both cases. \n\n### Training Algorithm\n\n#### Calculating Anomaly Score\n\nFor data point $x_i$, $S_i^{train}=L_n^{\\theta}(x_i)-L_a^{\\theta}(x_i)$. The score quantifies the effect of $y_i$ on minimizing $L(\\theta, y)$. The higher, the more normal. \n\n#### Estimating Labels\n\nThese scores are ranked, and the (1 − $\\alpha$)-quantile of the associated labels $y_i$ are assigned the value 0, and the remainder are assigned the value 1. \n\n#### Pseudo Code\n\n<img src=\"image-20220524234154108.png\" alt=\"image-20220524234154108\" style=\"zoom:67%;\" />\n\n### Inference\n\nIn practice we may not want to assume to encounter the same kinds of anomalies that the model encountered during training phase. Hence, the authors refrain from using $L_{\\theta}$ a during testing and score anomalies using only $L_{\\theta}^n$. Note that due to parameter sharing, training $L_{\\theta}^a$ jointly with $L_{\\theta}^n$ has already led to the desired information transfer between both losses. So $S_i^{test}=L_n^{\\theta}(x_i)$.\n\n## Evaluations\n\n### Experiment Setup\n\n#### Backbones\n\n* MHRot\n* NTL\n* ICL\n\n#### Datasets\n\n* Image\n  * CIFAR-10\n  * F-MNIST\n  * MVTEC\n* Tabular\n  * Arrhythmia\n  * Thyroid\n* Video\n  * UCSD\n\n### Results of Interest\n\n<img src=\"image-20220525002851926.png\" alt=\"image-20220525002851926\" style=\"zoom: 80%;\" />\n\n<img src=\"image-20220525003053189.png\" alt=\"image-20220525003053189\" style=\"zoom:80%;\" />\n\n## Ideas\n\n* EM algorithm\n* soft assignment with probabilities\n* in video anomaly detection, treat frames as data points and assign frame-level anomalous scores\n","tags":["Deep Learning","CV","Unsupervised Anomaly Detection"],"categories":["Paper Notes","CV","Anomaly Detection","Projects","Unsupervised Anomaly Detection","Image Anomaly Detection"]},{"title":"[LogicNLG] Logical Natural Language Generation from Open-Domain Tables","url":"/2022/05/24/LogicNLG/","content":"\n> Publication: 2020 ACL\n>\n> Links: [Paper](https://arxiv.org/abs/2004.10404), [Interpretation (CN)](https://blog.csdn.net/weixin_42802447/article/details/115366577), [Code](https://github.com/wenhuchen/LogicNLG)\n>\n> Key Words: NLG, table-to-text\n\n## Summary\n\nExisting NLG methods put limited emphasis on logical inference. The authors improved LM with such ability by a new training task called Logical NLG, accompanied with a new metric which evaluates the fidelity of the generated language. What’s more, they built a new dataset, providing a new testbed for logical inference. \n\n## Problem Statements & Background\n\nGiven a table, large pretrained LMs are able to generate fluent and coherent texts, but they lack fidelity: the generated text should be consistent with the underlying data, knowledge, or meaning representation. Recent work have proposed several methods to tackle surface-level fidelity problems, but actually they are just restating the facts in the underlying data. Here is an example:\n\n<img src=\"image-20220524151519647.png\" alt=\"image-20220524151519647\" style=\"zoom: 67%;\" />\n\nWe hope that the LM is able to generate beyond superficial facts by inferring the facts that can be entailed by the presented facts, like the ones shown in the box “Logical Natural Language Generation”. \n\n## Methods\n\n### New Task and New Metric\n\nTo equip LM with the stronger table-to-text generation ability, the authors propose a new task “logical NLG”, which means the generated texts should achieve high scores in **logical fidelity**. Existing IE-based metrics for evaluating generation have two major problems:\n\n<img src=\"image-20220524154947578.png\" alt=\"image-20220524154947578\" style=\"zoom: 67%;\" />\n\n To avoid these problems, the authors proposed several alternating automatic metrics:\n\n#### Parsing-based Evaluation\n\n It directly extracts the meaning representation from the generated sentence and executes it against the table to verify its correctness. \n\n<img src=\"image-20220524155657103.png\" alt=\"image-20220524155657103\" style=\"zoom: 67%;\" />\n\nThe sentence is represented by an expression (gray box), and then the expression could be executed against the table according to the fixed rule of the expression. \n\n#### NLI-based Evaluation\n\nThe NLI model is based on TableBERT, which linearizes the table into textual form and uses it as the evidence for natural language inference.\n\n<img src=\"image-20220524155727867.png\" alt=\"image-20220524155727867\" style=\"zoom:67%;\" />\n\n#### Adversarial Evaluation\n\nManually annotate adversarial examples for the test/validation set by simply changing minimum words to revert the logic of the sentence. Such adversarial examples preserve linguistic components like length and style except the logic-related words to specifically disentangle the generation model’s reasoning skill.\n\n<img src=\"image-20220524155755136.png\" alt=\"image-20220524155755136\" style=\"zoom:67%;\" />\n\n#### Discussion\n\n|      | Parsing-based (SP-Acc)                                       | NLI-based (NLI-Acc)                                          | Adversarial (Adv-Acc)                                        |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Pros | unbiased, as it measures the peak samples in the model’s likelihood | unbiased, as it measures the peak samples in the model’s likelihood | accurate in terms of reflecting the model’s reasoning capability on the given samples |\n| Cons | based on imperfect models, and thus evaluation score is inaccurate: more sensitive to number/calculation errors | based on imperfect models, and thus evaluation score is inaccurate: more sensitive to semantic errors | as the provided samples might not lie in the high-confidence area of the model’s distribution, it is biased in reflecting the model’s general reasoning capability |\n\n### New Dataset\n\nThe new dataset is built based on TabFact, a table-based fact-checking dataset with rich logical inferences in the annotated statements. This dataset contains rich logical inference, and every annotated sentence involves certain types of inference with minimum domain-specific knowledge. Sentences are made short, to focus on the problem of inference rather than linguistic complexity.\n\n<img src=\"image-20220524152917190.png\" alt=\"image-20220524152917190\" style=\"zoom: 50%;\" />\n\n### Training\n\n#### Adversarial Regularization\n\nFirst perform entity resolution to locate all the numbers, count, entities in the sentence and then randomly replace them with entities or numbers appearing in the table $T$. These perturbed samples are used as adversarial examples to regularize the model’s behavior.\n\n<img src=\"image-20220524170034608.png\" alt=\"image-20220524170034608\" style=\"zoom:67%;\" />\n\nMaximize the probability of correct samples, and minimize the probability of incorrect samples.\n\n#### Reinforcement Learning\n\nTo improve logical consistency of the generated sentence.\n\n<img src=\"image-20220524170251225.png\" alt=\"image-20220524170251225\" style=\"zoom: 67%;\" />\n\nThe full sentence receives a binary score $r(Y, T)$ from the semantic parser as reward, which denotes how good the sentence is, semantically.\n\n### Generation\n\nThe authors utilize coarse-to-fine generation to avoid the problem of mismatch between sequence order and logical order. \n\n<img src=\"image-20220524171228070.png\" alt=\"image-20220524171228070\" style=\"zoom:80%;\" />\n\nThe generation is composed of two phases:\n\n1. generate template. Use the entity linker to identify the entities and numbers in the original sentence $Y$ and replace them with placeholders.\n2. fill the placeholders. \n\n## Evaluations\n\n### Experiment Setup\n\n* Non-pretrained models: LSTM, Transformer\n* Pretrained models: Huggingface’s BERT & GPT-2\n\n### Results of Interest\n\n![image-20220524171658708](image-20220524171658708.png)\n\n## Conclusions\n\n1) Pre-Trained LM can significantly boost both the fluency and logical fidelity metrics\n2) RL and Adversarial Training are trading fluency for fidelity\n3) Coarse-to-Fine generation can help partially alleviate the fidelity issue while maintaining high language fluency\n","tags":["Deep Learning","NLP","NLG","Table-To-Text"],"categories":["Paper Notes","NLP","Projects","NLG","Table Pretraining"]},{"title":"[RTFM] Weakly-supervised Video Anomaly Detection with Robust Temporal Feature Magnitude Learning","url":"/2022/05/23/RTFM/","content":"\n> Publication: 2021 ICCV\n>\n> Links: [Paper](https://arxiv.org/pdf/2101.10030.pdf), [Interpretation (CN)](https://www.cnblogs.com/lhiker/articles/15599788.html), [Code](https://github.com/tianyu0207/RTFM)\n>\n> Key Words: Weakly Supervised Video Anomaly Detection, Multiple Instance Learning\n\n![image-20220523172333347](image-20220523172333347.png)\n\n## Summary\n\nExisting MIL loss has several drawbacks, and the authors improve the loss definition by using top-k selection and scoring segments according to feature magnitudes. \n\n## Problem Statements & Background\n\nGiven a video, the model is supposed to tell whether it contains anomaly events. In a weakly supervised scenario, the model is trained only with video-level labels, i.e. anomaly or not. Several past work have focused on multiple instance learning (MIL), which models the input video as a bag of video segments. The first version of MIL loss is defined by Sultani et al, which considers only the most anomaly segment in the video bag. If the model initially chooses a normal one and assigns a high score to it, this error would be exacerbated in the following training process; in addition, anomaly events usually occur in multiple segments of a video, and this MIL loss would result in the model's losing chances to learn on those valuable anomaly video segments. \n\n## Methods\n\nFirst, a video $X$ would break up into $T$ snippets. In practice, $T=32$. For each of the snippet $X_i$, it would be passed into a pretrained encoder (C3D, I3D) and become a feature $f_i$. And the features, denoted as $F={f_i}$ would then go to the MTN, which is illustrated below:\n\n<img src=\"image-20220523174001679.png\" alt=\"image-20220523174001679\" style=\"zoom:80%;\" />\n\nThis module is basically based on self-attention. After all these intermediate steps, $F$ would be mapped to $x$, with one $f_i$ corresponding to one $x_i$. Finally, a classifier is applied to $x$ and get a binary logits. \n\nTwo losses are defined for training:\n\n1.  improved MIL loss (RTFM loss): \n\n<img src=\"image-20220523174516365.png\" alt=\"image-20220523174516365\" style=\"zoom:67%;\" />\n\nThis loss aims at maximizing the separability between normal videos and abnormal videos. To define the separability:\n\n<img src=\"image-20220523174801028.png\" alt=\"image-20220523174801028\" style=\"zoom: 50%;\" />\n\n<img src=\"image-20220523174833204.png\" alt=\"image-20220523174833204\" style=\"zoom:50%;\" />\n\nwhere $g_{\\theta, k}$ is measuring the mean magnitude of the top-k features with highest magnitudes. \n\n2. binary classification loss:\n\n<img src=\"image-20220523174541257.png\" alt=\"image-20220523174541257\" style=\"zoom:67%;\" />\nThis is nothing but a binary cross-entropy loss.\n\n## Evaluations\n\n### Experiment Setup\n\ndatasets:\n\n* UCF-Crime\n* XD-Violence\n* Shanghai-Tech\n* UCSD-Peds\n\n### Results of Interest\n\n<img src=\"image-20220523175255139.png\" alt=\"image-20220523175255139\" style=\"zoom: 67%;\" />\n\n<img src=\"image-20220523175324561.png\" alt=\"image-20220523175324561\" style=\"zoom:67%;\" />\n","tags":["Deep Learning","CV","Weakly Supervised Video Anomaly Detection"],"categories":["Paper Notes","CV","Anomaly Detection","Projects","Video Anomaly Detection","Human Aggression Recognition"]},{"title":"[Turning Tables] Generating Examples from Semi-structured Tables for Endowing Language Models with Reasoning Skills","url":"/2022/05/21/turning-tables/","content":"\n> Publication: 2021\n>\n> Links: [Paper](https://arxiv.org/abs/2107.07261), [Code](https://github.com/oriyor/turning_tables)\n>\n> Key Words: reasoning, semi-structured table\n\n![image-20220515170620320](image-20220515170620320.png)\n\n## Summary\n\nExisting LMs lack reasoning skills, and the authors tackle this problem by pretraining LMs with semi-structured tables, which are used to generate different sets containing 16 kinds of question-context-answer triplets, in order to endow LMs with various reasoning skills.\n\n## Problem Statements & Background\n\nLarge pretrained LMs have been proved to struggle in performing symbolic reasoning operations. Past work on improving reasoning skills mainly have two flavors: 1) adding specialized components for specific skills (numerical reasoning, temporal reasoning), 2) generating synthetic examples at scale (using grammars, templates, question generation models).\n\n## Methods\n\nThe authors argue that **semi-structured tables** are a valuable resource for automatic generation of training data that will endow LMs with reasoning skills. Tables can be crawled from the web, and question-context-answer (q-c-a) triplets can be generated from the tables. \n\nExamples of q-c-a:\n\n<img src=\"image-20220515172904363.png\" alt=\"image-20220515172904363\" style=\"zoom: 67%;\" />\n\nFollowing is the overall architecture:\n\n<img src=\"image-20220515173107157.png\" alt=\"image-20220515173107157\" style=\"zoom: 67%;\" />\n\n### Data Generation\n\nThe authors generate table data by crawling tables from Wikipedia, and applying **16 different example generators (EGs)** on each table. Each EG corresponds to a particular reasoning skill (composition, numerical comparison, etc.), and comprises a small set of question templates. Variables in the templates are filled with content from the table, and the structure of the table allows to compute the answer automatically. The context is a list of facts generated from the table that contain facts required for answering the question as well as distractor facts.\n\n### Error-driven Sampling\n\nThe training process involves learning on multiple results from different EGs, so a proper multi-task training method is required. The authors make the training focus on the reasoning skills that the model still lacks, i.e. **error-driven sampling**. \n\nPast work have proposed uniform sampling, error sampling, etc.. An issue with error sampling is that if the error rate is high for a task and learning it is slow, the model will spend most time on that task at the expense of all other tasks, which may lead overall to low data efficiency. The authors put forward **momentum sampling**, which samples examples from a task in proportion to its rate of improvement, putting most probability mass on skills that are improving quickly.\n\n<img src=\"image-20220515181058227.png\" alt=\"image-20220515181058227\" style=\"zoom:67%;\" />\n\n### Finetune\n\nThe authors finetune the Pre-trained for Reasoning Model, **PReasM**, on three RC datasets that require reasoning: DROP, IIRC, and MMQA. \n\n## Evaluations\n\n### Experiment Setup\n\nModels\n\n* baseline: T5 (T5-base, T5-large)\n\nDatasets & Metrics\n\n* DROP: F1, EM\n* IIRC: F1, EM\n* MMQA: F1, EM\n\n### Results of Interest\n\n#### Performance on each dataset\n\n<img src=\"image-20220515181941958.png\" alt=\"image-20220515181941958\" style=\"zoom:67%;\" />\n\n#### Effect of new sampling strategy\n\n<img src=\"image-20220515182134219.png\" alt=\"image-20220515182134219\" style=\"zoom:67%;\" />","tags":["Deep Learning","NLP","Table Pretraining","Reasoning"],"categories":["Paper Notes","NLP","Projects","Table Pretraining"]},{"title":"Hexo Manual","url":"/2022/05/21/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n<!--more-->\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","categories":["Documentations"]}]