[{"title":"[RTFM] Weakly-supervised Video Anomaly Detection with Robust Temporal Feature Magnitude Learning","url":"/2022/05/23/RTFM/","content":"<blockquote>\n<p>Publication: 2021 ICCV</p>\n<p>Links: [Paper](<a href=\"https://arxiv.org/pdf/2101.10030.pdf\">https://arxiv.org/pdf/2101.10030.pdf</a>, <a href=\"https://www.cnblogs.com/lhiker/articles/15599788.html\">Interpretation (CN)</a>, <a href=\"https://github.com/tianyu0207/RTFM\">Code</a></p>\n<p>Key Words: Weakly Supervised Video Anomaly Detection, Multiple Instance Learning</p>\n</blockquote>\n<p><img src=\"/2022/05/23/RTFM/image-20220523172333347.png\" alt=\"image-20220523172333347\"></p>\n<h2 id=\"summary\"><a class=\"markdownIt-Anchor\" href=\"#summary\"></a> Summary</h2>\n<p>Existing MIL loss has several drawbacks, and the authors improve the loss definition by using top-k selection and scoring segments according to feature magnitudes.</p>\n<h2 id=\"problem-statements-background\"><a class=\"markdownIt-Anchor\" href=\"#problem-statements-background\"></a> Problem Statements &amp; Background</h2>\n<p>Given a video, the model is supposed to tell whether it contains anomaly events. In weakly supervised senario, the model is trained only with video-level labels, i.e. anomaly or not. Several past work have focused on multiple instance learning (MIL), which models the input video as a bag of video segments. The first version of MIL loss is defined by Sultani et al, which considers only the most anomaly segment in the video bag. If the model initially chooses a normal one and assigns a high score to it, this error would be exacerbated in the following training process; in addition, anomaly events usually occur in multiple segments of a video, and this MIL loss would result in the model’s losing chances to learn on those valuable anomaly video segments.</p>\n<h2 id=\"methods\"><a class=\"markdownIt-Anchor\" href=\"#methods\"></a> Methods</h2>\n<p>First, a video <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span> would break up into <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span></span></span></span> snippets. In practice, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>T</mi><mo>=</mo><mn>32</mn></mrow><annotation encoding=\"application/x-tex\">T=32</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">2</span></span></span></span>. For each of the snippet <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">X_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>, it would be passed into a pretrained encoder (C3D, I3D) and become a feature <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">f_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>. And the features, denoted as <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi><mo>=</mo><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">F={f_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> would then go to the MTN, which is illustrated below:</p>\n<img src=\"/2022/05/23/RTFM/image-20220523174001679.png\" alt=\"image-20220523174001679\" style=\"zoom:80%;\">\n<p>This module is basically based on self-attention. After all these intermediate steps, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span> would be mapped to <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>, with one <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">f_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> corresponding to one <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>. Finally, a classifier is applied to <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span> and get a binary logits.</p>\n<p>Two losses are defined for training:</p>\n<ol>\n<li>improved MIL loss (RTFM loss):</li>\n</ol>\n   <img src=\"/2022/05/23/RTFM/image-20220523174516365.png\" alt=\"image-20220523174516365\" style=\"zoom:67%;\">\n<p>This loss aims at maximizing the separability between normal videos and abnormal videos. To define the separability:</p>\n   <img src=\"/2022/05/23/RTFM/image-20220523174801028.png\" alt=\"image-20220523174801028\" style=\"zoom: 50%;\">\n   <img src=\"/2022/05/23/RTFM/image-20220523174833204.png\" alt=\"image-20220523174833204\" style=\"zoom:50%;\">\n<p>where <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>g</mi><mrow><mi>θ</mi><mo separator=\"true\">,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">g_{\\theta, k}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> is measuring the mean magnitude of the top-k features with highest magnitudes.</p>\n<ol start=\"2\">\n<li>\n<p>binary classification loss:</p>\n<img src=\"/2022/05/23/RTFM/image-20220523174541257.png\" alt=\"image-20220523174541257\" style=\"zoom:67%;\">\n<p>This is nothing but a binary cross-entropy loss.</p>\n</li>\n</ol>\n<h2 id=\"evaluations\"><a class=\"markdownIt-Anchor\" href=\"#evaluations\"></a> Evaluations</h2>\n<h3 id=\"experiment-setup\"><a class=\"markdownIt-Anchor\" href=\"#experiment-setup\"></a> Experiment Setup</h3>\n<p>datasets:</p>\n<ul>\n<li>UCF-Crime</li>\n<li>XD-Violence</li>\n<li>Shanghai-Tech</li>\n<li>UCSD-Peds</li>\n</ul>\n<h3 id=\"results-of-interest\"><a class=\"markdownIt-Anchor\" href=\"#results-of-interest\"></a> Results of Interest</h3>\n<img src=\"/2022/05/23/RTFM/image-20220523175255139.png\" alt=\"image-20220523175255139\" style=\"zoom: 67%;\">\n<img src=\"/2022/05/23/RTFM/image-20220523175324561.png\" alt=\"image-20220523175324561\" style=\"zoom:67%;\">\n","categories":["Paper Notes","CV","Anomaly Detection","Video Anomaly Detection"],"tags":["Deep Learning","CV"]},{"title":"[LogicNLG] Logical Natural Language Generation from Open-Domain Tables","url":"/2022/05/24/LogicNLG/","content":"<blockquote>\n<p>Publication: 2020 ACL</p>\n<p>Links: <a href=\"https://arxiv.org/abs/2004.10404\">Paper</a>, <a href=\"https://blog.csdn.net/weixin_42802447/article/details/115366577\">Interpretation (CN)</a>, <a href=\"https://github.com/wenhuchen/LogicNLG\">Code</a></p>\n<p>Key Words: NLG, table-to-text</p>\n</blockquote>\n<h2 id=\"summary\"><a class=\"markdownIt-Anchor\" href=\"#summary\"></a> Summary</h2>\n<p>Existing NLG methods put limited emphasis on logical inference. The authors improved LM with such ability by a new training task called Logical NLG, accompanied with a new metric which evaluates the fidelity of the generated language. What’s more, they built a new dataset, providing a new testbed for logical inference.</p>\n<h2 id=\"problem-statements-background\"><a class=\"markdownIt-Anchor\" href=\"#problem-statements-background\"></a> Problem Statements &amp; Background</h2>\n<p>Given a table, large pretrained LMs are able to generate fluent and coherent texts, but they lack fidelity: the generated text should be consistent with the underlying data, knowledge, or meaning representation. Recent work have proposed several methods to tackle surface-level fidelity problems, but actually they are just restating the facts in the underlying data. Here is an example:</p>\n<img src=\"/2022/05/24/LogicNLG/image-20220524151519647.png\" alt=\"image-20220524151519647\" style=\"zoom: 67%;\">\n<p>We hope that the LM is able to generate beyond superficial facts by inferring the facts that can be entailed by the presented facts, like the ones shown in the box “Logical Natural Language Generation”.</p>\n<h2 id=\"methods\"><a class=\"markdownIt-Anchor\" href=\"#methods\"></a> Methods</h2>\n<h3 id=\"new-task-and-new-metric\"><a class=\"markdownIt-Anchor\" href=\"#new-task-and-new-metric\"></a> New Task and New Metric</h3>\n<p>To equip LM with the stronger table-to-text generation ability, the authors propose a new task “logical NLG”, which means the generated texts should achieve high scores in <strong>logical fidelity</strong>. Existing IE-based metrics for evaluating generation have two major problems:</p>\n<img src=\"/2022/05/24/LogicNLG/image-20220524154947578.png\" alt=\"image-20220524154947578\" style=\"zoom: 67%;\">\n<p>To avoid these problems, the authors proposed several alternating automatic metrics:</p>\n<h4 id=\"parsing-based-evaluation\"><a class=\"markdownIt-Anchor\" href=\"#parsing-based-evaluation\"></a> Parsing-based Evaluation</h4>\n<p>It directly extracts the meaning representation from the generated sentence and executes it against the table to verify its correctness.</p>\n<img src=\"/2022/05/24/LogicNLG/image-20220524155657103.png\" alt=\"image-20220524155657103\" style=\"zoom: 67%;\">\n<p>The sentence is represented by an expression (gray box), and then the expression could be executed against the table according to the fixed rule of the expression.</p>\n<h4 id=\"nli-based-evaluation\"><a class=\"markdownIt-Anchor\" href=\"#nli-based-evaluation\"></a> NLI-based Evaluation</h4>\n<p>The NLI model is based on TableBERT, which linearizes the table into textual form and uses it as the evidence for natural language inference.</p>\n<img src=\"/2022/05/24/LogicNLG/image-20220524155727867.png\" alt=\"image-20220524155727867\" style=\"zoom:67%;\">\n<h4 id=\"adversarial-evaluation\"><a class=\"markdownIt-Anchor\" href=\"#adversarial-evaluation\"></a> Adversarial Evaluation</h4>\n<p>Manually annotate adversarial examples for the test/validation set by simply changing minimum words to revert the logic of the sentence. Such adversarial examples preserve linguistic components like length and style except the logic-related words to specifically disentangle the generation model’s reasoning skill.</p>\n<img src=\"/2022/05/24/LogicNLG/image-20220524155755136.png\" alt=\"image-20220524155755136\" style=\"zoom:67%;\">\n<h4 id=\"discussion\"><a class=\"markdownIt-Anchor\" href=\"#discussion\"></a> Discussion</h4>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Parsing-based (SP-Acc)</th>\n<th>NLI-based (NLI-Acc)</th>\n<th>Adversarial (Adv-Acc)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Pros</td>\n<td>unbiased, as it measures the peak samples in the model’s likelihood</td>\n<td>unbiased, as it measures the peak samples in the model’s likelihood</td>\n<td>accurate in terms of reflecting the model’s reasoning capability on the given samples</td>\n</tr>\n<tr>\n<td>Cons</td>\n<td>based on imperfect models, and thus evaluation score is inaccurate: more sensitive to number/calculation errors</td>\n<td>based on imperfect models, and thus evaluation score is inaccurate: more sensitive to semantic errors</td>\n<td>as the provided samples might not lie in the high-confidence area of the model’s distribution, it is biased in reflecting the model’s general reasoning capability</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"new-dataset\"><a class=\"markdownIt-Anchor\" href=\"#new-dataset\"></a> New Dataset</h3>\n<p>The new dataset is built based on TabFact, a table-based fact-checking dataset with rich logical inferences in the annotated statements. This dataset contains rich logical inference, and every annotated sentence involves certain types of inference with minimum domain-specific knowledge. Sentences are made short, to focus on the problem of inference rather than linguistic complexity.</p>\n<img src=\"/2022/05/24/LogicNLG/image-20220524152917190.png\" alt=\"image-20220524152917190\" style=\"zoom: 50%;\">\n<h3 id=\"training\"><a class=\"markdownIt-Anchor\" href=\"#training\"></a> Training</h3>\n<h4 id=\"adversarial-regularization\"><a class=\"markdownIt-Anchor\" href=\"#adversarial-regularization\"></a> Adversarial Regularization</h4>\n<p>First perform entity resolution to locate all the numbers, count, entities in the sentence and then randomly replace them with entities or numbers appearing in the table <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span></span></span></span>. These perturbed samples are used as adversarial examples to regularize the model’s behavior.</p>\n<img src=\"/2022/05/24/LogicNLG/image-20220524170034608.png\" alt=\"image-20220524170034608\" style=\"zoom:67%;\">\n<p>Maximize the probability of correct samples, and minimize the probability of incorrect samples.</p>\n<h4 id=\"reinforcement-learning\"><a class=\"markdownIt-Anchor\" href=\"#reinforcement-learning\"></a> Reinforcement Learning</h4>\n<p>To improve logical consistency of the generated sentence.</p>\n<img src=\"/2022/05/24/LogicNLG/image-20220524170251225.png\" alt=\"image-20220524170251225\" style=\"zoom: 67%;\">\n<p>The full sentence receives a binary score <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>r</mi><mo stretchy=\"false\">(</mo><mi>Y</mi><mo separator=\"true\">,</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">r(Y, T)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span></span></span></span> from the semantic parser as reward, which denotes how good the sentence is, semantically.</p>\n<h3 id=\"generation\"><a class=\"markdownIt-Anchor\" href=\"#generation\"></a> Generation</h3>\n<p>The authors utilize coarse-to-fine generation to avoid the problem of mismatch between sequence order and logical order.</p>\n<img src=\"/2022/05/24/LogicNLG/image-20220524171228070.png\" alt=\"image-20220524171228070\" style=\"zoom:80%;\">\n<p>The generation is composed of two phases:</p>\n<ol>\n<li>generate template. Use the entity linker to identify the entities and numbers in the original sentence <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">Y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span></span></span></span> and replace them with placeholders.</li>\n<li>fill the placeholders.</li>\n</ol>\n<h2 id=\"evaluations\"><a class=\"markdownIt-Anchor\" href=\"#evaluations\"></a> Evaluations</h2>\n<h3 id=\"experiment-setup\"><a class=\"markdownIt-Anchor\" href=\"#experiment-setup\"></a> Experiment Setup</h3>\n<ul>\n<li>Non-pretrained models: LSTM, Transformer</li>\n<li>Pretrained models: Huggingface’s BERT &amp; GPT-2</li>\n</ul>\n<h3 id=\"results-of-interest\"><a class=\"markdownIt-Anchor\" href=\"#results-of-interest\"></a> Results of Interest</h3>\n<p><img src=\"/2022/05/24/LogicNLG/image-20220524171658708.png\" alt=\"image-20220524171658708\"></p>\n<h2 id=\"conclusions\"><a class=\"markdownIt-Anchor\" href=\"#conclusions\"></a> Conclusions</h2>\n<ol>\n<li>Pre-Trained LM can significantly boost both the fluency and logical fidelity metrics</li>\n<li>RL and Adversarial Training are trading fluency for fidelity</li>\n<li>Coarse-to-Fine generation can help partially alleviate the fidelity issue while maintaining high language fluency</li>\n</ol>\n","categories":["Paper Notes","NLP","NLG"],"tags":["Deep Learning","NLP"]},{"title":"Hexo Manual","url":"/2022/05/21/hello-world/","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<span id=\"more\"></span>\n<h2 id=\"quick-start\"><a class=\"markdownIt-Anchor\" href=\"#quick-start\"></a> Quick Start</h2>\n<h3 id=\"create-a-new-post\"><a class=\"markdownIt-Anchor\" href=\"#create-a-new-post\"></a> Create a new post</h3>\n<pre class=\"highlight\"><code class=\"bash\">$ hexo new <span class=\"hljs-string\">\"My New Post\"</span>\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"run-server\"><a class=\"markdownIt-Anchor\" href=\"#run-server\"></a> Run server</h3>\n<pre class=\"highlight\"><code class=\"bash\">$ hexo server\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"generate-static-files\"><a class=\"markdownIt-Anchor\" href=\"#generate-static-files\"></a> Generate static files</h3>\n<pre class=\"highlight\"><code class=\"bash\">$ hexo generate\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"deploy-to-remote-sites\"><a class=\"markdownIt-Anchor\" href=\"#deploy-to-remote-sites\"></a> Deploy to remote sites</h3>\n<pre class=\"highlight\"><code class=\"bash\">$ hexo deploy\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","categories":["Documentations"]},{"title":"[Turning Tables] Generating Examples from Semi-structured Tables for Endowing Language Models with Reasoning Skills","url":"/2022/05/21/turning-tables/","content":"<blockquote>\n<p>Publication: 2021</p>\n<p>Links: <a href=\"https://arxiv.org/abs/2107.07261\">Paper</a>, <a href=\"https://github.com/oriyor/turning_tables\">Code</a></p>\n<p>Key Words: reasoning, semi-structured table</p>\n</blockquote>\n<p><img src=\"/2022/05/21/turning-tables/image-20220515170620320.png\" alt=\"image-20220515170620320\"></p>\n<h2 id=\"summary\"><a class=\"markdownIt-Anchor\" href=\"#summary\"></a> Summary</h2>\n<p>Existing LMs lack reasoning skills, and the authors tackle this problem by pretraining LMs with semi-structured tables, which are used to generate different sets containing 16 kinds of question-context-answer triplets, in order to endow LMs with various reasoning skills.</p>\n<h2 id=\"problem-statements-background\"><a class=\"markdownIt-Anchor\" href=\"#problem-statements-background\"></a> Problem Statements &amp; Background</h2>\n<p>Large pretrained LMs have been proved to struggle in performing symbolic reasoning operations. Past work on improving reasoning skills mainly have two flavors: 1) adding specialized components for specific skills (numerical reasoning, temporal reasoning), 2) generating synthetic examples at scale (using grammars, templates, question generation models).</p>\n<h2 id=\"methods\"><a class=\"markdownIt-Anchor\" href=\"#methods\"></a> Methods</h2>\n<p>The authors argue that <strong>semi-structured tables</strong> are a valuable resource for automatic generation of training data that will endow LMs with reasoning skills. Tables can be crawled from the web, and question-context-answer (q-c-a) triplets can be generated from the tables.</p>\n<p>Examples of q-c-a:</p>\n<img src=\"/2022/05/21/turning-tables/image-20220515172904363.png\" alt=\"image-20220515172904363\" style=\"zoom: 67%;\">\n<p>Following is the overall architecture:</p>\n<img src=\"/2022/05/21/turning-tables/image-20220515173107157.png\" alt=\"image-20220515173107157\" style=\"zoom: 67%;\">\n<h3 id=\"data-generation\"><a class=\"markdownIt-Anchor\" href=\"#data-generation\"></a> Data Generation</h3>\n<p>The authors generate table data by crawling tables from Wikipedia, and applying <strong>16 different example generators (EGs)</strong> on each table. Each EG corresponds to a particular reasoning skill (composition, numerical comparison, etc.), and comprises a small set of question templates. Variables in the templates are filled with content from the table, and the structure of the table allows to compute the answer automatically. The context is a list of facts generated from the table that contain facts required for answering the question as well as distractor facts.</p>\n<h3 id=\"error-driven-sampling\"><a class=\"markdownIt-Anchor\" href=\"#error-driven-sampling\"></a> Error-driven Sampling</h3>\n<p>The training process involves learning on multiple results from different EGs, so a proper multi-task training method is required. The authors make the training focus on the reasoning skills that the model still lacks, i.e. <strong>error-driven sampling</strong>.</p>\n<p>Past work have proposed uniform sampling, error sampling, etc… An issue with error sampling is that if the error rate is high for a task and learning it is slow, the model will spend most time on that task at the expense of all other tasks, which may lead overall to low data efficiency. The authors put forward <strong>momentum sampling</strong>, which samples examples from a task in proportion to its rate of improvement, putting most probability mass on skills that are improving quickly.</p>\n<img src=\"/2022/05/21/turning-tables/image-20220515181058227.png\" alt=\"image-20220515181058227\" style=\"zoom:67%;\">\n<h3 id=\"finetune\"><a class=\"markdownIt-Anchor\" href=\"#finetune\"></a> Finetune</h3>\n<p>The authors finetune the Pre-trained for Reasoning Model, <strong>PReasM</strong>, on three RC datasets that require reasoning: DROP, IIRC, and MMQA.</p>\n<h2 id=\"evaluations\"><a class=\"markdownIt-Anchor\" href=\"#evaluations\"></a> Evaluations</h2>\n<h3 id=\"experiment-setup\"><a class=\"markdownIt-Anchor\" href=\"#experiment-setup\"></a> Experiment Setup</h3>\n<p>Models</p>\n<ul>\n<li>baseline: T5 (T5-base, T5-large)</li>\n</ul>\n<p>Datasets &amp; Metrics</p>\n<ul>\n<li>DROP: F1, EM</li>\n<li>IIRC: F1, EM</li>\n<li>MMQA: F1, EM</li>\n</ul>\n<h3 id=\"results-of-interest\"><a class=\"markdownIt-Anchor\" href=\"#results-of-interest\"></a> Results of Interest</h3>\n<h4 id=\"performance-on-each-dataset\"><a class=\"markdownIt-Anchor\" href=\"#performance-on-each-dataset\"></a> Performance on each dataset</h4>\n<img src=\"/2022/05/21/turning-tables/image-20220515181941958.png\" alt=\"image-20220515181941958\" style=\"zoom:67%;\">\n<h4 id=\"effect-of-new-sampling-strategy\"><a class=\"markdownIt-Anchor\" href=\"#effect-of-new-sampling-strategy\"></a> Effect of new sampling strategy</h4>\n<img src=\"/2022/05/21/turning-tables/image-20220515182134219.png\" alt=\"image-20220515182134219\" style=\"zoom:67%;\">","categories":["Paper Notes","NLP"],"tags":["Deep Learning","NLP"]}]